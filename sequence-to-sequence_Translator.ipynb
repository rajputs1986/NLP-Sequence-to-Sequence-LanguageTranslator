{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\n",
    "#http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dietary-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "abandoned-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure variables\n",
    "batch_size = 65\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fallen-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Info\n",
    "file_name = 'fra.txt'\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_chars = set()\n",
    "target_chars = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "trying-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read from File and initialize variables\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    all_lines = f.read().split('\\n')\n",
    "    for line in all_lines[:min(num_samples, len(all_lines)-1)]:\n",
    "        input_text, target_text, _ = line.split('\\t')\n",
    "        input_texts.append(input_text)\n",
    "        target_text = '\\t'+target_text+'\\n'\n",
    "        target_texts.append(target_text)\n",
    "        \n",
    "        for ch in input_text:\n",
    "            if ch not in input_chars:\n",
    "                input_chars.add(ch)\n",
    "                \n",
    "        for ch in target_text:\n",
    "            if ch not in target_chars:\n",
    "                target_chars.add(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "mature-modeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(input_texts) #10000\n",
    "len(target_texts) #10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "finnish-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(input_chars) #71\n",
    "len(target_chars) #93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "seasonal-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = sorted(list(input_chars))\n",
    "target_chars = sorted(list(target_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "neural-venture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 ; 93\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(input_chars)\n",
    "num_decoder_tokens = len(target_chars)\n",
    "print(num_encoder_tokens,';',num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "incomplete-ideal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 ; 59\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in target_texts])\n",
    "print(max_encoder_seq_length,';',max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "sitting-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input char to index\n",
    "input_token_index = dict([(ch, i) for i,ch in enumerate(input_chars)])\n",
    "#input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "classified-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input char to index\n",
    "target_token_index = dict([(ch, i) for i,ch in enumerate(target_chars)])\n",
    "#target_token_index\n",
    "reverse_target_char_index = dict([(i, ch) for i,ch in enumerate(target_chars)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "sitting-difficulty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "rubber-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((num_samples,max_encoder_seq_length,num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((num_samples,max_decoder_seq_length,num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((num_samples,max_decoder_seq_length,num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "damaged-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "mysterious-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#char-wise One-hot-encoding of data\n",
    "for i, (input_text,target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    \n",
    "    for j,char in enumerate(input_text):\n",
    "        encoder_input_data[i, j, input_token_index[char]] = 1\n",
    "    encoder_input_data[i, j+1:, input_token_index[' ']] = 1\n",
    "    \n",
    "    for k,char in enumerate(target_text):\n",
    "        decoder_input_data[i, k, target_token_index[char]] = 1\n",
    "        \n",
    "        #target data is 1 ahead in time step\n",
    "        if (k>0):\n",
    "            decoder_target_data[i, k-1, target_token_index[char]] = 1\n",
    "    decoder_input_data[i, k+1:, target_token_index[' ']] = 1\n",
    "    decoder_target_data[i, k:, target_token_index[' ']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "burning-safety",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 15, 71)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "stainless-senior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 59, 93)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "reserved-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "modular-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "brilliant-watson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, None, 71)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, None, 93)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 256), (None, 335872      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  358400      input_10[0][0]                   \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 93)     23901       lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 718,173\n",
      "Trainable params: 718,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# plot the model\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)\n",
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "medieval-pottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "124/124 [==============================] - 35s 285ms/step - loss: 1.1358 - accuracy: 0.7351 - val_loss: 1.0478 - val_accuracy: 0.7131\n",
      "Epoch 2/100\n",
      "124/124 [==============================] - 32s 261ms/step - loss: 0.8326 - accuracy: 0.7754 - val_loss: 0.8572 - val_accuracy: 0.7638\n",
      "Epoch 3/100\n",
      "124/124 [==============================] - 32s 260ms/step - loss: 0.6795 - accuracy: 0.8104 - val_loss: 0.7437 - val_accuracy: 0.7893\n",
      "Epoch 4/100\n",
      "124/124 [==============================] - 33s 268ms/step - loss: 0.5904 - accuracy: 0.8293 - val_loss: 0.6865 - val_accuracy: 0.7976\n",
      "Epoch 5/100\n",
      "124/124 [==============================] - 33s 263ms/step - loss: 0.5406 - accuracy: 0.8423 - val_loss: 0.6432 - val_accuracy: 0.8129\n",
      "Epoch 6/100\n",
      "124/124 [==============================] - 33s 268ms/step - loss: 0.5047 - accuracy: 0.8523 - val_loss: 0.6201 - val_accuracy: 0.8182\n",
      "Epoch 7/100\n",
      "124/124 [==============================] - 34s 278ms/step - loss: 0.4754 - accuracy: 0.8599 - val_loss: 0.5829 - val_accuracy: 0.8262\n",
      "Epoch 8/100\n",
      "124/124 [==============================] - 34s 271ms/step - loss: 0.4505 - accuracy: 0.8668 - val_loss: 0.5661 - val_accuracy: 0.8329\n",
      "Epoch 9/100\n",
      "124/124 [==============================] - 35s 285ms/step - loss: 0.4297 - accuracy: 0.8723 - val_loss: 0.5490 - val_accuracy: 0.8368\n",
      "Epoch 10/100\n",
      "124/124 [==============================] - 36s 288ms/step - loss: 0.4109 - accuracy: 0.8776 - val_loss: 0.5395 - val_accuracy: 0.8422\n",
      "Epoch 11/100\n",
      "124/124 [==============================] - 35s 285ms/step - loss: 0.3941 - accuracy: 0.8823 - val_loss: 0.5205 - val_accuracy: 0.8463\n",
      "Epoch 12/100\n",
      "124/124 [==============================] - 38s 308ms/step - loss: 0.3784 - accuracy: 0.8870 - val_loss: 0.5125 - val_accuracy: 0.8496\n",
      "Epoch 13/100\n",
      "124/124 [==============================] - 36s 293ms/step - loss: 0.3638 - accuracy: 0.8910 - val_loss: 0.5046 - val_accuracy: 0.8531\n",
      "Epoch 14/100\n",
      "124/124 [==============================] - 37s 302ms/step - loss: 0.3498 - accuracy: 0.8955 - val_loss: 0.4971 - val_accuracy: 0.8541\n",
      "Epoch 15/100\n",
      "124/124 [==============================] - 41s 329ms/step - loss: 0.3373 - accuracy: 0.8986 - val_loss: 0.5001 - val_accuracy: 0.8546\n",
      "Epoch 16/100\n",
      "124/124 [==============================] - 42s 343ms/step - loss: 0.3247 - accuracy: 0.9022 - val_loss: 0.4985 - val_accuracy: 0.8548\n",
      "Epoch 17/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.3131 - accuracy: 0.9060 - val_loss: 0.5072 - val_accuracy: 0.8536\n",
      "Epoch 18/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.3026 - accuracy: 0.9088 - val_loss: 0.4812 - val_accuracy: 0.8596\n",
      "Epoch 19/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.2919 - accuracy: 0.9119 - val_loss: 0.4758 - val_accuracy: 0.8626\n",
      "Epoch 20/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.2817 - accuracy: 0.9147 - val_loss: 0.4812 - val_accuracy: 0.8641\n",
      "Epoch 21/100\n",
      "124/124 [==============================] - 43s 343ms/step - loss: 0.2718 - accuracy: 0.9180 - val_loss: 0.4873 - val_accuracy: 0.8607\n",
      "Epoch 22/100\n",
      "124/124 [==============================] - 37s 299ms/step - loss: 0.2634 - accuracy: 0.9203 - val_loss: 0.4640 - val_accuracy: 0.8686\n",
      "Epoch 23/100\n",
      "124/124 [==============================] - 38s 310ms/step - loss: 0.2543 - accuracy: 0.9229 - val_loss: 0.4695 - val_accuracy: 0.8680\n",
      "Epoch 24/100\n",
      "124/124 [==============================] - 39s 316ms/step - loss: 0.2462 - accuracy: 0.9254 - val_loss: 0.4765 - val_accuracy: 0.8663\n",
      "Epoch 25/100\n",
      "124/124 [==============================] - 36s 294ms/step - loss: 0.2378 - accuracy: 0.9279 - val_loss: 0.4766 - val_accuracy: 0.8672\n",
      "Epoch 26/100\n",
      "124/124 [==============================] - 40s 323ms/step - loss: 0.2303 - accuracy: 0.9301 - val_loss: 0.4734 - val_accuracy: 0.8701\n",
      "Epoch 27/100\n",
      "124/124 [==============================] - 43s 344ms/step - loss: 0.2233 - accuracy: 0.9323 - val_loss: 0.4754 - val_accuracy: 0.8685\n",
      "Epoch 28/100\n",
      "124/124 [==============================] - 50s 407ms/step - loss: 0.2160 - accuracy: 0.9342 - val_loss: 0.4812 - val_accuracy: 0.8688\n",
      "Epoch 29/100\n",
      "124/124 [==============================] - 52s 421ms/step - loss: 0.2092 - accuracy: 0.9366 - val_loss: 0.4830 - val_accuracy: 0.8693\n",
      "Epoch 30/100\n",
      "124/124 [==============================] - 46s 371ms/step - loss: 0.2028 - accuracy: 0.9382 - val_loss: 0.4779 - val_accuracy: 0.8715\n",
      "Epoch 31/100\n",
      "124/124 [==============================] - 46s 368ms/step - loss: 0.1970 - accuracy: 0.9400 - val_loss: 0.4929 - val_accuracy: 0.8671\n",
      "Epoch 32/100\n",
      "124/124 [==============================] - 46s 372ms/step - loss: 0.1912 - accuracy: 0.9416 - val_loss: 0.4901 - val_accuracy: 0.8697\n",
      "Epoch 33/100\n",
      "124/124 [==============================] - 63s 507ms/step - loss: 0.1847 - accuracy: 0.9436 - val_loss: 0.5132 - val_accuracy: 0.8670\n",
      "Epoch 34/100\n",
      "124/124 [==============================] - 50s 403ms/step - loss: 0.1802 - accuracy: 0.9452 - val_loss: 0.4948 - val_accuracy: 0.8699\n",
      "Epoch 35/100\n",
      "124/124 [==============================] - 40s 323ms/step - loss: 0.1751 - accuracy: 0.9465 - val_loss: 0.5126 - val_accuracy: 0.8670\n",
      "Epoch 36/100\n",
      "124/124 [==============================] - 41s 328ms/step - loss: 0.1699 - accuracy: 0.9480 - val_loss: 0.5084 - val_accuracy: 0.8686\n",
      "Epoch 37/100\n",
      "124/124 [==============================] - 38s 305ms/step - loss: 0.1652 - accuracy: 0.9493 - val_loss: 0.5133 - val_accuracy: 0.8702\n",
      "Epoch 38/100\n",
      "124/124 [==============================] - 36s 294ms/step - loss: 0.1609 - accuracy: 0.9506 - val_loss: 0.5173 - val_accuracy: 0.8689\n",
      "Epoch 39/100\n",
      "124/124 [==============================] - 36s 287ms/step - loss: 0.1567 - accuracy: 0.9518 - val_loss: 0.5319 - val_accuracy: 0.8647\n",
      "Epoch 40/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.1524 - accuracy: 0.9531 - val_loss: 0.5142 - val_accuracy: 0.8714\n",
      "Epoch 41/100\n",
      "124/124 [==============================] - 36s 288ms/step - loss: 0.1480 - accuracy: 0.9545 - val_loss: 0.5293 - val_accuracy: 0.8691\n",
      "Epoch 42/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.1444 - accuracy: 0.9554 - val_loss: 0.5563 - val_accuracy: 0.8668\n",
      "Epoch 43/100\n",
      "124/124 [==============================] - 39s 317ms/step - loss: 0.1406 - accuracy: 0.9567 - val_loss: 0.5293 - val_accuracy: 0.8700\n",
      "Epoch 44/100\n",
      "124/124 [==============================] - 38s 307ms/step - loss: 0.1368 - accuracy: 0.9579 - val_loss: 0.5298 - val_accuracy: 0.8718\n",
      "Epoch 45/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.1338 - accuracy: 0.9588 - val_loss: 0.5491 - val_accuracy: 0.8707\n",
      "Epoch 46/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.1302 - accuracy: 0.9598 - val_loss: 0.5509 - val_accuracy: 0.8691\n",
      "Epoch 47/100\n",
      "124/124 [==============================] - 36s 288ms/step - loss: 0.1269 - accuracy: 0.9605 - val_loss: 0.5488 - val_accuracy: 0.8710\n",
      "Epoch 48/100\n",
      "124/124 [==============================] - 36s 294ms/step - loss: 0.1239 - accuracy: 0.9614 - val_loss: 0.5589 - val_accuracy: 0.8698\n",
      "Epoch 49/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.1211 - accuracy: 0.9622 - val_loss: 0.5621 - val_accuracy: 0.8702\n",
      "Epoch 50/100\n",
      "124/124 [==============================] - 37s 300ms/step - loss: 0.1182 - accuracy: 0.9631 - val_loss: 0.5668 - val_accuracy: 0.8718\n",
      "Epoch 51/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.1155 - accuracy: 0.9643 - val_loss: 0.5667 - val_accuracy: 0.8710\n",
      "Epoch 52/100\n",
      "124/124 [==============================] - 36s 293ms/step - loss: 0.1126 - accuracy: 0.9650 - val_loss: 0.5685 - val_accuracy: 0.8709\n",
      "Epoch 53/100\n",
      "124/124 [==============================] - 37s 298ms/step - loss: 0.1100 - accuracy: 0.9657 - val_loss: 0.5827 - val_accuracy: 0.8692\n",
      "Epoch 54/100\n",
      "124/124 [==============================] - 38s 307ms/step - loss: 0.1076 - accuracy: 0.9664 - val_loss: 0.5809 - val_accuracy: 0.8699\n",
      "Epoch 55/100\n",
      "124/124 [==============================] - 39s 314ms/step - loss: 0.1056 - accuracy: 0.9669 - val_loss: 0.5867 - val_accuracy: 0.8718\n",
      "Epoch 56/100\n",
      "124/124 [==============================] - 36s 293ms/step - loss: 0.1028 - accuracy: 0.9679 - val_loss: 0.5978 - val_accuracy: 0.8697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "124/124 [==============================] - 37s 298ms/step - loss: 0.1010 - accuracy: 0.9683 - val_loss: 0.5937 - val_accuracy: 0.8705\n",
      "Epoch 58/100\n",
      "124/124 [==============================] - 37s 299ms/step - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.5903 - val_accuracy: 0.8716\n",
      "Epoch 59/100\n",
      "124/124 [==============================] - 37s 295ms/step - loss: 0.0966 - accuracy: 0.9695 - val_loss: 0.6081 - val_accuracy: 0.8686\n",
      "Epoch 60/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.6081 - val_accuracy: 0.8702\n",
      "Epoch 61/100\n",
      "124/124 [==============================] - 36s 286ms/step - loss: 0.0929 - accuracy: 0.9703 - val_loss: 0.6060 - val_accuracy: 0.8728\n",
      "Epoch 62/100\n",
      "124/124 [==============================] - 35s 286ms/step - loss: 0.0909 - accuracy: 0.9710 - val_loss: 0.6169 - val_accuracy: 0.8690\n",
      "Epoch 63/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.0891 - accuracy: 0.9716 - val_loss: 0.6178 - val_accuracy: 0.8708\n",
      "Epoch 64/100\n",
      "124/124 [==============================] - 36s 288ms/step - loss: 0.0871 - accuracy: 0.9720 - val_loss: 0.6254 - val_accuracy: 0.8700\n",
      "Epoch 65/100\n",
      "124/124 [==============================] - 35s 284ms/step - loss: 0.0861 - accuracy: 0.9724 - val_loss: 0.6417 - val_accuracy: 0.8681\n",
      "Epoch 66/100\n",
      "124/124 [==============================] - 36s 294ms/step - loss: 0.0844 - accuracy: 0.9729 - val_loss: 0.6366 - val_accuracy: 0.8702\n",
      "Epoch 67/100\n",
      "124/124 [==============================] - 35s 285ms/step - loss: 0.0824 - accuracy: 0.9734 - val_loss: 0.6468 - val_accuracy: 0.8692\n",
      "Epoch 68/100\n",
      "124/124 [==============================] - 36s 287ms/step - loss: 0.0807 - accuracy: 0.9738 - val_loss: 0.6531 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "124/124 [==============================] - 36s 290ms/step - loss: 0.0794 - accuracy: 0.9744 - val_loss: 0.6462 - val_accuracy: 0.8705\n",
      "Epoch 70/100\n",
      "124/124 [==============================] - 36s 287ms/step - loss: 0.0778 - accuracy: 0.9748 - val_loss: 0.6499 - val_accuracy: 0.8711\n",
      "Epoch 71/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.0768 - accuracy: 0.9751 - val_loss: 0.6660 - val_accuracy: 0.8675\n",
      "Epoch 72/100\n",
      "124/124 [==============================] - 35s 285ms/step - loss: 0.0755 - accuracy: 0.9754 - val_loss: 0.6622 - val_accuracy: 0.8689\n",
      "Epoch 73/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.0739 - accuracy: 0.9758 - val_loss: 0.6657 - val_accuracy: 0.8696\n",
      "Epoch 74/100\n",
      "124/124 [==============================] - 38s 308ms/step - loss: 0.0732 - accuracy: 0.9760 - val_loss: 0.6660 - val_accuracy: 0.8706\n",
      "Epoch 75/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.0717 - accuracy: 0.9767 - val_loss: 0.6764 - val_accuracy: 0.8707\n",
      "Epoch 76/100\n",
      "124/124 [==============================] - 36s 290ms/step - loss: 0.0704 - accuracy: 0.9768 - val_loss: 0.6918 - val_accuracy: 0.8683\n",
      "Epoch 77/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.0691 - accuracy: 0.9771 - val_loss: 0.6787 - val_accuracy: 0.8705\n",
      "Epoch 78/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.6734 - val_accuracy: 0.8713\n",
      "Epoch 79/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.0669 - accuracy: 0.9778 - val_loss: 0.6746 - val_accuracy: 0.8708\n",
      "Epoch 80/100\n",
      "124/124 [==============================] - 36s 288ms/step - loss: 0.0660 - accuracy: 0.9779 - val_loss: 0.6890 - val_accuracy: 0.8710\n",
      "Epoch 81/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.0652 - accuracy: 0.9783 - val_loss: 0.7002 - val_accuracy: 0.8673\n",
      "Epoch 82/100\n",
      "124/124 [==============================] - 40s 319ms/step - loss: 0.0642 - accuracy: 0.9786 - val_loss: 0.7005 - val_accuracy: 0.8698\n",
      "Epoch 83/100\n",
      "124/124 [==============================] - 37s 300ms/step - loss: 0.0632 - accuracy: 0.9786 - val_loss: 0.6978 - val_accuracy: 0.8703\n",
      "Epoch 84/100\n",
      "124/124 [==============================] - 37s 295ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.6982 - val_accuracy: 0.8697\n",
      "Epoch 85/100\n",
      "124/124 [==============================] - 37s 295ms/step - loss: 0.0613 - accuracy: 0.9792 - val_loss: 0.6964 - val_accuracy: 0.8704\n",
      "Epoch 86/100\n",
      "124/124 [==============================] - 39s 313ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.7096 - val_accuracy: 0.8698\n",
      "Epoch 87/100\n",
      "124/124 [==============================] - 38s 310ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 0.7066 - val_accuracy: 0.8699\n",
      "Epoch 88/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.7278 - val_accuracy: 0.8678\n",
      "Epoch 89/100\n",
      "124/124 [==============================] - 36s 290ms/step - loss: 0.0581 - accuracy: 0.9800 - val_loss: 0.7138 - val_accuracy: 0.8691\n",
      "Epoch 90/100\n",
      "124/124 [==============================] - 36s 287ms/step - loss: 0.0570 - accuracy: 0.9804 - val_loss: 0.7171 - val_accuracy: 0.8696\n",
      "Epoch 91/100\n",
      "124/124 [==============================] - 37s 297ms/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 0.7259 - val_accuracy: 0.8695\n",
      "Epoch 92/100\n",
      "124/124 [==============================] - 36s 292ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.7398 - val_accuracy: 0.8680\n",
      "Epoch 93/100\n",
      "124/124 [==============================] - 38s 303ms/step - loss: 0.0550 - accuracy: 0.9811 - val_loss: 0.7229 - val_accuracy: 0.8688\n",
      "Epoch 94/100\n",
      "124/124 [==============================] - 38s 304ms/step - loss: 0.0539 - accuracy: 0.9813 - val_loss: 0.7332 - val_accuracy: 0.8690\n",
      "Epoch 95/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.0535 - accuracy: 0.9815 - val_loss: 0.7299 - val_accuracy: 0.8708\n",
      "Epoch 96/100\n",
      "124/124 [==============================] - 36s 294ms/step - loss: 0.0530 - accuracy: 0.9816 - val_loss: 0.7314 - val_accuracy: 0.8695\n",
      "Epoch 97/100\n",
      "124/124 [==============================] - 36s 290ms/step - loss: 0.0518 - accuracy: 0.9819 - val_loss: 0.7384 - val_accuracy: 0.8700\n",
      "Epoch 98/100\n",
      "124/124 [==============================] - 36s 289ms/step - loss: 0.0514 - accuracy: 0.9818 - val_loss: 0.7425 - val_accuracy: 0.8705\n",
      "Epoch 99/100\n",
      "124/124 [==============================] - 37s 297ms/step - loss: 0.0507 - accuracy: 0.9822 - val_loss: 0.7416 - val_accuracy: 0.8698\n",
      "Epoch 100/100\n",
      "124/124 [==============================] - 36s 291ms/step - loss: 0.0497 - accuracy: 0.9826 - val_loss: 0.7572 - val_accuracy: 0.8686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17126ec7790>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs,\n",
    "         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "incoming-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "funny-central",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17154952a60>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "senior-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "automatic-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "comparable-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentence = ''\n",
    "def decode_sequence1(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    \n",
    "    # Sample a token\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    print(sampled_token_index, ':', reverse_target_char_index[sampled_token_index])\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "aboriginal-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "Input setence: Go.\n",
      "Decoded setence: Bouge !\n",
      "\n",
      "----\n",
      "Input setence: Go.\n",
      "Decoded setence: Bouge !\n",
      "\n",
      "----\n",
      "Input setence: Go.\n",
      "Decoded setence: Bouge !\n",
      "\n",
      "----\n",
      "Input setence: Hi.\n",
      "Decoded setence: Salut.\n",
      "\n",
      "----\n",
      "Input setence: Hi.\n",
      "Decoded setence: Salut.\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run!\n",
      "Decoded setence: File !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Run.\n",
      "Decoded setence: Fuyons !\n",
      "\n",
      "----\n",
      "Input setence: Who?\n",
      "Decoded setence: Qui ?\n",
      "\n",
      "----\n",
      "Input setence: Wow!\n",
      "Decoded setence: Ça alors !\n",
      "\n",
      "----\n",
      "Input setence: Fire!\n",
      "Decoded setence: Au feu !\n",
      "\n",
      "----\n",
      "Input setence: Help!\n",
      "Decoded setence: À l'aide !\n",
      "\n",
      "----\n",
      "Input setence: Jump!\n",
      "Decoded setence: Saute.\n",
      "\n",
      "----\n",
      "Input setence: Jump.\n",
      "Decoded setence: Saute.\n",
      "\n",
      "----\n",
      "Input setence: Stop!\n",
      "Decoded setence: Arrête-toi !\n",
      "\n",
      "----\n",
      "Input setence: Stop!\n",
      "Decoded setence: Arrête-toi !\n",
      "\n",
      "----\n",
      "Input setence: Stop!\n",
      "Decoded setence: Arrête-toi !\n",
      "\n",
      "----\n",
      "Input setence: Wait!\n",
      "Decoded setence: Attendez !\n",
      "\n",
      "----\n",
      "Input setence: Wait!\n",
      "Decoded setence: Attendez !\n",
      "\n",
      "----\n",
      "Input setence: Wait!\n",
      "Decoded setence: Attendez !\n",
      "\n",
      "----\n",
      "Input setence: Wait.\n",
      "Decoded setence: Attendez.\n",
      "\n",
      "----\n",
      "Input setence: Wait.\n",
      "Decoded setence: Attendez.\n",
      "\n",
      "----\n",
      "Input setence: Wait.\n",
      "Decoded setence: Attendez.\n",
      "\n",
      "----\n",
      "Input setence: Wait.\n",
      "Decoded setence: Attendez.\n",
      "\n",
      "----\n",
      "Input setence: Begin.\n",
      "Decoded setence: Commencez.\n",
      "\n",
      "----\n",
      "Input setence: Begin.\n",
      "Decoded setence: Commencez.\n",
      "\n",
      "----\n",
      "Input setence: Go on.\n",
      "Decoded setence: Poursuis.\n",
      "\n",
      "----\n",
      "Input setence: Go on.\n",
      "Decoded setence: Poursuis.\n",
      "\n",
      "----\n",
      "Input setence: Go on.\n",
      "Decoded setence: Poursuis.\n",
      "\n",
      "----\n",
      "Input setence: Hello!\n",
      "Decoded setence: Salut !\n",
      "\n",
      "----\n",
      "Input setence: Hello!\n",
      "Decoded setence: Salut !\n",
      "\n",
      "----\n",
      "Input setence: I see.\n",
      "Decoded setence: Je les couris.\n",
      "\n",
      "----\n",
      "Input setence: I see.\n",
      "Decoded setence: Je les couris.\n",
      "\n",
      "----\n",
      "Input setence: I try.\n",
      "Decoded setence: J'essaye.\n",
      "\n",
      "----\n",
      "Input setence: I won!\n",
      "Decoded setence: J'ai gagné !\n",
      "\n",
      "----\n",
      "Input setence: I won!\n",
      "Decoded setence: J'ai gagné !\n",
      "\n",
      "----\n",
      "Input setence: I won.\n",
      "Decoded setence: J'arrive à le skier.\n",
      "\n",
      "----\n",
      "Input setence: Oh no!\n",
      "Decoded setence: Oh non !\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Relax.\n",
      "Decoded setence: Détends-toi.\n",
      "\n",
      "----\n",
      "Input setence: Smile.\n",
      "Decoded setence: Souriez !\n",
      "\n",
      "----\n",
      "Input setence: Smile.\n",
      "Decoded setence: Souriez !\n",
      "\n",
      "----\n",
      "Input setence: Smile.\n",
      "Decoded setence: Souriez !\n",
      "\n",
      "----\n",
      "Input setence: Attack!\n",
      "Decoded setence: Attaquez !\n",
      "\n",
      "----\n",
      "Input setence: Attack!\n",
      "Decoded setence: Attaquez !\n",
      "\n",
      "----\n",
      "Input setence: Attack!\n",
      "Decoded setence: Attaquez !\n",
      "\n",
      "----\n",
      "Input setence: Cheers!\n",
      "Decoded setence: Santé !\n",
      "\n",
      "----\n",
      "Input setence: Cheers!\n",
      "Decoded setence: Santé !\n",
      "\n",
      "----\n",
      "Input setence: Cheers!\n",
      "Decoded setence: Santé !\n",
      "\n",
      "----\n",
      "Input setence: Cheers!\n",
      "Decoded setence: Santé !\n",
      "\n",
      "----\n",
      "Input setence: Eat it.\n",
      "Decoded setence: Mange-le.\n",
      "\n",
      "----\n",
      "Input setence: Eat it.\n",
      "Decoded setence: Mange-le.\n",
      "\n",
      "----\n",
      "Input setence: Get up.\n",
      "Decoded setence: Lève-toi.\n",
      "\n",
      "----\n",
      "Input setence: Get up.\n",
      "Decoded setence: Lève-toi.\n",
      "\n",
      "----\n",
      "Input setence: Go now.\n",
      "Decoded setence: Vas-y maintenant.\n",
      "\n",
      "----\n",
      "Input setence: Go now.\n",
      "Decoded setence: Vas-y maintenant.\n",
      "\n",
      "----\n",
      "Input setence: Go now.\n",
      "Decoded setence: Vas-y maintenant.\n",
      "\n",
      "----\n",
      "Input setence: Got it!\n",
      "Decoded setence: Aha !\n",
      "\n",
      "----\n",
      "Input setence: Got it!\n",
      "Decoded setence: Aha !\n",
      "\n",
      "----\n",
      "Input setence: Got it!\n",
      "Decoded setence: Aha !\n",
      "\n",
      "----\n",
      "Input setence: Got it?\n",
      "Decoded setence: Compris ?\n",
      "\n",
      "----\n",
      "Input setence: Got it?\n",
      "Decoded setence: Compris ?\n",
      "\n",
      "----\n",
      "Input setence: Got it?\n",
      "Decoded setence: Compris ?\n",
      "\n",
      "----\n",
      "Input setence: Hop in.\n",
      "Decoded setence: Monte.\n",
      "\n",
      "----\n",
      "Input setence: Hop in.\n",
      "Decoded setence: Monte.\n",
      "\n",
      "----\n",
      "Input setence: Hug me.\n",
      "Decoded setence: Serre-moi dans tes bras !\n",
      "\n",
      "----\n",
      "Input setence: Hug me.\n",
      "Decoded setence: Serre-moi dans tes bras !\n",
      "\n",
      "----\n",
      "Input setence: I fell.\n",
      "Decoded setence: Je suis demandée sonjoures.\n",
      "\n",
      "----\n",
      "Input setence: I fell.\n",
      "Decoded setence: Je suis demandée sonjoures.\n",
      "\n",
      "----\n",
      "Input setence: I fled.\n",
      "Decoded setence: J'ai revé.\n",
      "\n",
      "----\n",
      "Input setence: I knit.\n",
      "Decoded setence: J'ai temps.\n",
      "\n",
      "----\n",
      "Input setence: I know.\n",
      "Decoded setence: Je trais au breveaux.\n",
      "\n",
      "----\n",
      "Input setence: I left.\n",
      "Decoded setence: Je les ai laissés y aller.\n",
      "\n",
      "----\n",
      "Input setence: I left.\n",
      "Decoded setence: Je les ai laissés y aller.\n",
      "\n",
      "----\n",
      "Input setence: I lied.\n",
      "Decoded setence: Je les appré.\n",
      "\n",
      "----\n",
      "Input setence: I lost.\n",
      "Decoded setence: J'ai perdu.\n",
      "\n",
      "----\n",
      "Input setence: I paid.\n",
      "Decoded setence: J’ai parlé.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index : seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('----')\n",
    "    print('Input setence:', input_texts[seq_index])\n",
    "    print('Decoded setence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
